\chapter{Evaluation} \label{C:evaluation}
The section covers the evaluation of the Kihi Runner. Specifically, this section analyses the results of the aforementioned benchmark suites on the final version of the Kihi Runner. It begins with an analysis of the micro benchmarks which examine the individual elements of the Kihi Runner. This is followed by the macro benchmarks which examine the performance of these optimisations against a small set of representative benchmark programs.

\section{Method}
All these benchmarks and graphs were autogenerated by the benchmark suite. The instructions for reproducing these benchmarks are provided in the project's readme which can be found on Gitlab. These specific benchmarks were run on a computer with an i5-4670K CPU @ 3.40GHZ and 8GB of 2400MHZ RAM.

\section{Micro Benchmarks}
This section includes benchmarks on compilation time and operator evaluation. The compilation time analysis looks at how optimisation level and program length affect compilation time. The operator evaluation analysis looks at how operators handle abstractions of varying length and successive applications. The latter is essentially a test of the effectiveness of the optimised representation. These benchmarks are executor agnostic as there is no need to find an operator when the program consists of only one operator.

\subsection{Compilation vs Program Length}
\input{figures/04_results/compilation_results}
Compilation consists of up to three stages: parsing, symbol detection, and symbol optimisation. The optimisation level determines the number of stages in the compilation. Optimisation level 0 only includes parsing, whilst level 2 includes all three. The results in figure \ref{fig:compilation_results} illustrate how compilation time changes as program length increases for varying optimisation levels. The results show that whilst level 0 scales approximately linearly with program length, level 1 and 2 scale superlinearly. Interestingly however, optimisation level 2 incurs almost no additional cost over just level 1.

The linear behaviour of level 0 is unsurprising because the parser is a simple linear algorithm that simply performs a single pass through the source code. However, the superlinear behaviour of level 1 is surprising because the symbol detection algorithm is also linear. This is most likely due to the memory allocation and initialisation that potentially happens on each term. As the program grows larger the size of the memory allocation increases in tandem with the frequency of memory allocations resulting in $\theta(n^2)$ complexity. The negligible cost of symbol optimisation is also surprising, and can be attributed to the small number and size of symbols that need to be optimised. In the case of this program, there are only eight symbols with at most six terms regardless of program length due to repetition. Since the symbol optimisation algorithm scales linearly with symbol size and symbol count it becomes negligible as the program size increases.

\subsection{Operators}
\subsubsection{Operator vs Abstraction Length}
\input{figures/04_results/basic_operator_results}
Figure \ref{fig:basic_operator_results} shows the performance of the standard and symbolic operators on abstractions of varying length. A symbolic operator is an operator that has been converted into a symbol and optimised. The results show that all operators appear to scale linearly with abstraction size. This is unsurprising, as the most expensive aspects of operator evaluation are memory allocation and initialisation, both operations that scale linearly with the size of the abstraction. The results also show that symbolic optimisation is not a cost-free optimisation. There is a fixed overhead to utilising the optimised representation. However, the performance of the optimised representation degrades at approximately the same rate as the unoptimised version. This overhead is likely due to the machinery required to shift from standard execution to optimised execution. Specifically, the process of gathering abstractions for the optimised representation requires a non-negligible amount of work.

\subsubsection{Repeated Operator Application}
\input{figures/04_results/repeated_operator_results}
Figure \ref{fig:repeated_operator_results} shows that for repeated applications of left and right, the optimised encodings have substantially better performance. In contrast to the non-optimised versions which display exponentially worsening performance, the optimised versions appear to scale linearly. This significant performance boost is likely due to the optimised representation's ability to evaluate the entire series of operators in one find and replace scan. This stands in contrast to the unoptimised representation which must repeatedly manipulate the system's state.

\section{Macro Benchmarks}
This section provides benchmarks of the Kihi Runner on real Kihi programs. This section first describes the programs being used as benchmarks, and establishes why they are appropriate. 

\subsection{Benchmark Programs}
An effort has been made to ensure the benchmark programs are representative of typical Kihi programs, but this is difficult because Kihi is not an ordinary programming language. However, what has been attempted is finding programs with a variety of operator distributions and structures in order to provide good coverage of the potential program space. Structures here referring to the encodings, such as church numerals, used in the program. This led to the choice of three main benchmark programs:

\begin{figure}[H]
\centering
\begin{enumerate}
    \item \textbf{Count}; Outputs all the natural numbers (as church numerals) in order.
    \item \textbf{Count\_Bind}; Outputs all the natural numbers (as church numerals) in order using a bind stucture \cite{jones2018practice}.
    \item \textbf{Count\_List}; Outputs all the natural numbers (as church numerals) in order using a list stucture \cite{jones2018practice}.
\end{enumerate}
\end{figure}

The instruction distributions of these programs are shown in figure \ref{fig:program_term_distribution}. The distribution shown provides decent coverage of the variety of terms, and potential distributions. Apply is necessarily common because it is the only mechanism that can extend the length of the program.

\input{figures/04_results/program_term_distribution}

\subsection{Analysis}
Figures \ref{fig:reduce_count_performance} to \ref{fig:reduce_count_list_performance} demonstrate the reduce executors performance on the various count programs at varying optimisation levels. These figures show that optimisation level 1 provides a significant boost to Kihi Runner's performance in general across all programs. This stands in contrast to optimisation level 2 which only provides a slight improvement to performance on `count' and `count\_list', and provides no noticeable improvement to `count\_bind'. This suggests that the optimisation algorithm is unable to effectively decode the structure underlying `count\_bind'.

Figures \ref{fig:reduce_count_efficiency} to \ref{fig:reduce_count_list_efficiency} demonstrate the efficiency of the reduce executor at various optimisation levels. Perhaps surprisingly, optimisation level 1 increases the number of instructions that must be executed in order to compute the same number of outputs. This is due to the additional symbol expansion step required in order to process a symbol. Symbol expansion simply refers to the process of replacing a symbol with its corresponding terms. However, at optimisation level 2, the number of instructions decreases below level 0. This is because level 2 introduces the ability to execute symbols directly by utilising the find and replace algorithm. This not only removes the need for symbol expansion but also potentially captures multiple terms into a single execution step.

Overall, these figures suggest that the major performance gains are due to more efficient handling of memory. The fact that optimisation level 1, which replaces sequences of terms with an equivalent symbol, provides the majority of the performance boost strongly suggests that minimising the size and frequency of memory allocations and manipulations provides the greatest performance benefits. 

\input{figures/04_results/reduce_executor_performance_on_count}
\input{figures/04_results/reduce_executor_efficiency_on_count}

